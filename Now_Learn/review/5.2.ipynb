{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5132],\n",
       "        [-0.5195]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,3),nn.ReLU(),nn.Linear(3,1))\n",
    "X=torch.rand(size=(2,4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.2947, -0.2525, -0.1051, -0.2648, -0.0816,  0.1219, -0.3384, -0.1254],\n",
      "        [ 0.2486, -0.1987, -0.2989,  0.1334, -0.3271, -0.2164, -0.1493, -0.3097],\n",
      "        [ 0.2249,  0.1312,  0.0759, -0.3254,  0.0879, -0.1533,  0.0591, -0.1869]])), ('bias', tensor([0.0198, 0.0163, 0.2073]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2441, 0.3490, 0.7298, 0.8838],\n",
       "         [0.8737, 0.6903, 0.1954, 0.4962]]),\n",
       " None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([3, 8])) ('2.bias', torch.Size([3])) ('4.weight', torch.Size([1, 3])) ('4.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name,param.shape) for name,param in net[0].named_parameters()])\n",
    "print(*[(name,param.shape) for name,param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2947, -0.2525, -0.1051, -0.2648, -0.0816,  0.1219, -0.3384, -0.1254],\n",
       "        [ 0.2486, -0.1987, -0.2989,  0.1334, -0.3271, -0.2164, -0.1493, -0.3097],\n",
       "        [ 0.2249,  0.1312,  0.0759, -0.3254,  0.0879, -0.1533,  0.0591, -0.1869]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.weight'].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.ReLU(),\n",
    "                         nn.Linear(8,4),nn.ReLU())\n",
    "def block2():\n",
    "    net=nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block{i}',block1())\n",
    "    return net\n",
    "\n",
    "rgnet=nn.Sequential(block2(),nn.Linear(4,1))\n",
    "rgnet(X)\n",
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4685,  0.3036,  0.4363,  0.2000],\n",
       "        [ 0.2382,  0.0945, -0.0775,  0.4470],\n",
       "        [ 0.1262,  0.0683,  0.1765, -0.2977],\n",
       "        [-0.3620, -0.3652,  0.1775,  0.1875],\n",
       "        [-0.2608, -0.1693,  0.1493, -0.2715],\n",
       "        [-0.2127, -0.0243,  0.1648,  0.1160],\n",
       "        [ 0.1343,  0.0385, -0.4220, -0.0825],\n",
       "        [ 0.0292, -0.1485,  0.1165,  0.1347]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][0][0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0052, -0.0049, -0.0021, -0.0116]), tensor(0.))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,mean=0,std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0],net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.],\n",
       "          [42., 42., 42., 42.]], requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.7001,  0.1961, -0.1171, -0.1157,  0.7302,  0.0582, -0.0231, -0.2691],\n",
       "          [-0.4763,  0.6837,  0.4123, -0.6394, -0.5517, -0.3025, -0.6500, -0.3842],\n",
       "          [-0.2024,  0.5203, -0.4632, -0.2551, -0.7007, -0.0167,  0.4860, -0.3722]],\n",
       "         requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0.], requires_grad=True)),\n",
       " ('4.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[1., 1., 1.]], requires_grad=True)),\n",
       " ('4.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.], requires_grad=True))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.constant_(net[0].weight,42),nn.init.xavier_uniform_(net[2].weight)\n",
    "[(name,val) for name,val in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "share=nn.Linear(8,8)\n",
    "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),\n",
    "                  share,nn.ReLU(),\n",
    "                  share,nn.ReLU(),\n",
    "                  nn.Linear(8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0818, -0.0307,  0.1169,  0.1259,  0.1910,  0.3404, -0.2367, -0.1646],\n",
       "         [ 0.2913,  0.2734,  0.3110,  0.3159, -0.2864,  0.3011,  0.1717,  0.2176],\n",
       "         [ 0.2264, -0.0256, -0.2207,  0.3417,  0.3219, -0.1769,  0.0041, -0.0359],\n",
       "         [-0.2393,  0.3513,  0.0805, -0.0057,  0.2193, -0.1385, -0.2252,  0.1113],\n",
       "         [ 0.0225,  0.1112, -0.2339,  0.1512,  0.2952, -0.0957, -0.0757, -0.1552],\n",
       "         [-0.2563,  0.0234, -0.1865,  0.3160, -0.0643,  0.3270, -0.2952, -0.1985],\n",
       "         [ 0.2066, -0.0891,  0.2912, -0.0707, -0.2795, -0.1327,  0.3109,  0.2682],\n",
       "         [-0.2845,  0.1283,  0.1615, -0.0273, -0.2996, -0.3374, -0.2339,  0.0760]]),\n",
       " tensor([-0.0818, -0.0307,  0.1169,  0.1259,  0.1910,  0.3404, -0.2367, -0.1646]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data,net[2].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True]]),\n",
       " tensor([[-0.0818, -0.0307,  0.1169,  0.1259,  0.1910,  0.3404, -0.2367, -0.1646],\n",
       "         [ 0.2913,  0.2734,  0.3110,  0.3159, -0.2864,  0.3011,  0.1717,  0.2176],\n",
       "         [ 0.2264, -0.0256, -0.2207,  0.3417,  0.3219, -0.1769,  0.0041, -0.0359],\n",
       "         [-0.2393,  0.3513,  0.0805, -0.0057,  0.2193, -0.1385, -0.2252,  0.1113],\n",
       "         [ 0.0225,  0.1112, -0.2339,  0.1512,  0.2952, -0.0957, -0.0757, -0.1552],\n",
       "         [-0.2563,  0.0234, -0.1865,  0.3160, -0.0643,  0.3270, -0.2952, -0.1985],\n",
       "         [ 0.2066, -0.0891,  0.2912, -0.0707, -0.2795, -0.1327,  0.3109,  0.2682],\n",
       "         [-0.2845,  0.1283,  0.1615, -0.0273, -0.2996, -0.3374, -0.2339,  0.0760]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data==net[4].weight.data,net[4].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "net[2].weight.data+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9182, 0.9693, 1.1169, 1.1259, 1.1910, 1.3404, 0.7633, 0.8354],\n",
      "        [1.2913, 1.2734, 1.3110, 1.3159, 0.7136, 1.3011, 1.1717, 1.2176],\n",
      "        [1.2264, 0.9744, 0.7793, 1.3417, 1.3219, 0.8231, 1.0041, 0.9641],\n",
      "        [0.7607, 1.3513, 1.0805, 0.9943, 1.2193, 0.8615, 0.7748, 1.1113],\n",
      "        [1.0225, 1.1112, 0.7661, 1.1512, 1.2952, 0.9043, 0.9243, 0.8448],\n",
      "        [0.7437, 1.0234, 0.8135, 1.3160, 0.9357, 1.3270, 0.7048, 0.8015],\n",
      "        [1.2066, 0.9109, 1.2912, 0.9293, 0.7205, 0.8673, 1.3109, 1.2682],\n",
      "        [0.7155, 1.1283, 1.1615, 0.9727, 0.7004, 0.6626, 0.7661, 1.0760]])\n",
      "tensor([[0.9182, 0.9693, 1.1169, 1.1259, 1.1910, 1.3404, 0.7633, 0.8354],\n",
      "        [1.2913, 1.2734, 1.3110, 1.3159, 0.7136, 1.3011, 1.1717, 1.2176],\n",
      "        [1.2264, 0.9744, 0.7793, 1.3417, 1.3219, 0.8231, 1.0041, 0.9641],\n",
      "        [0.7607, 1.3513, 1.0805, 0.9943, 1.2193, 0.8615, 0.7748, 1.1113],\n",
      "        [1.0225, 1.1112, 0.7661, 1.1512, 1.2952, 0.9043, 0.9243, 0.8448],\n",
      "        [0.7437, 1.0234, 0.8135, 1.3160, 0.9357, 1.3270, 0.7048, 0.8015],\n",
      "        [1.2066, 0.9109, 1.2912, 0.9293, 0.7205, 0.8673, 1.3109, 1.2682],\n",
      "        [0.7155, 1.1283, 1.1615, 0.9727, 0.7004, 0.6626, 0.7661, 1.0760]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net[4].weight.data[:]),print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
