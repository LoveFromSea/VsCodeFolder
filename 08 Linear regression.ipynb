{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function normal:\n",
      "\n",
      "normal(...)\n",
      "    normal(mean, std, *, generator=None, out=None) -> Tensor\n",
      "    \n",
      "    Returns a tensor of random numbers drawn from separate normal distributions\n",
      "    whose mean and standard deviation are given.\n",
      "    \n",
      "    The :attr:`mean` is a tensor with the mean of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The :attr:`std` is a tensor with the standard deviation of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
      "    total number of elements in each tensor need to be the same.\n",
      "    \n",
      "    .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
      "              is used as the shape for the returned output tensor\n",
      "    \n",
      "    .. note:: When :attr:`std` is a CUDA tensor, this function synchronizes\n",
      "              its device with the CPU.\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "    \n",
      "    Keyword args:\n",
      "        generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
      "        tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
      "                  8.0505,   8.1408,   9.0563,  10.0566])\n",
      "    \n",
      "    .. function:: normal(mean=0.0, std, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the means are shared among all drawn\n",
      "    elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (float, optional): the mean for all distributions\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
      "        tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
      "    \n",
      "    .. function:: normal(mean, std=1.0, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the standard deviations are shared among\n",
      "    all drawn elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (float, optional): the standard deviation for all distributions\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 6.))\n",
      "        tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
      "    \n",
      "    .. function:: normal(mean, std, size, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the means and standard deviations are shared\n",
      "    among all drawn elements. The resulting tensor has size given by :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        mean (float): the mean for all distributions\n",
      "        std (float): the standard deviation for all distributions\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(2, 3, size=(1, 4))\n",
      "        tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3660, -0.4343],\n",
      "        [-0.6493,  1.8723],\n",
      "        [ 0.2125,  0.8028],\n",
      "        ...,\n",
      "        [-1.8472, -2.2531],\n",
      "        [ 0.3957,  0.0685],\n",
      "        [-0.5608, -0.1272]])\n"
     ]
    }
   ],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    print(X)\n",
    "    y = torch.matmul(X, w)+b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([ 0.3660, -0.4343]) \n",
      "label: tensor([6.3991])\n"
     ]
    }
   ],
   "source": [
    "print('features:',features[0],'\\nlabel:',labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:,1].detach().numpy(),\n",
    "                labels.detach().numpy(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2689,  0.0158],\n",
      "        [-1.7664,  0.4002],\n",
      "        [ 0.5735,  0.3602],\n",
      "        [ 0.8999, -0.6389],\n",
      "        [-1.6422,  1.0380],\n",
      "        [-0.5518, -0.3375],\n",
      "        [ 0.3059,  0.0739],\n",
      "        [ 1.6047, -0.0619],\n",
      "        [ 0.4191, -1.2123],\n",
      "        [ 0.0099, -1.4424]]) \n",
      " tensor([[ 6.7064],\n",
      "        [-0.7068],\n",
      "        [ 4.1067],\n",
      "        [ 8.1816],\n",
      "        [-2.6336],\n",
      "        [ 4.2312],\n",
      "        [ 4.5541],\n",
      "        [ 7.6254],\n",
      "        [ 9.1575],\n",
      "        [ 9.1312]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i:min(i+batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.normal(0,0.01,size=(2,1),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "def linreg(X,w,b):\n",
    "    return torch.matmul(X,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat,y):\n",
    "    return (y_hat-y.reshape(y_hat.shape))**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param-=lr*param.grad/batch_size\n",
    "            param.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss0.000056\n",
      "epoch2,loss0.000052\n",
      "epoch3,loss0.000063\n",
      "epoch4,loss0.000059\n",
      "epoch5,loss0.000052\n",
      "epoch6,loss0.000056\n",
      "epoch7,loss0.000051\n",
      "epoch8,loss0.000060\n",
      "epoch9,loss0.000053\n",
      "epoch10,loss0.000067\n"
     ]
    }
   ],
   "source": [
    "lr=0.5\n",
    "num_epochs=10\n",
    "net=linreg\n",
    "loss=squared_loss\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(batch_size,features,labels):\n",
    "        l=loss(net(X,w,b),y)\n",
    "        l.sum().backward()\n",
    "        sgd([w,b],lr,batch_size)\n",
    "    with torch.no_grad():\n",
    "        train_l=loss(net(features,w,b),labels)\n",
    "        print(f'epoch{epoch+1},loss{float(train_l.mean()):f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差: tensor([-0.0004, -0.0011], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([0.0004], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "n_features,n_labels=d2l.synthetic_data(true_w,true_b,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "data_iter=load_array((n_features,n_labels),batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4857, -0.9905],\n",
       "         [ 0.5617,  0.9734],\n",
       "         [-0.1256, -1.4230],\n",
       "         [-0.0514,  1.1140],\n",
       "         [ 1.1074, -0.4128],\n",
       "         [-0.6682,  1.8131],\n",
       "         [-0.5490, -0.0806],\n",
       "         [-2.6437, -0.6787],\n",
       "         [ 1.1380,  0.2109],\n",
       "         [ 0.1517, -1.7266]]),\n",
       " tensor([[ 8.5431],\n",
       "         [ 2.0120],\n",
       "         [ 8.7950],\n",
       "         [ 0.3071],\n",
       "         [ 7.8291],\n",
       "         [-3.3172],\n",
       "         [ 3.3832],\n",
       "         [ 1.2283],\n",
       "         [ 5.7548],\n",
       "         [10.3861]])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "n_net=nn.Sequential(nn.Linear(2,1)) # 第一个指定输入特征形状，即2,权重有两个，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_net[0].weight.data.normal_(0,0.01)\n",
    "n_net[0].bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss0.000236\n",
      "epoch2,loss0.000101\n",
      "epoch3,loss0.000105\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(n_net.parameters(), lr=0.03)\n",
    "n_num_epochs = 3\n",
    "for epoch in range(n_num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(n_net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l=loss(n_net(features),labels)\n",
    "    print(f'epoch{epoch+1},loss{l:f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差： tensor([0.0003, 0.0015])\n",
      "b的估计误差： tensor([-0.0005])\n"
     ]
    }
   ],
   "source": [
    "w = n_net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = n_net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
