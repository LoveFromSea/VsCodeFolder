# 分类VS回归
- 回归估计一个连续值
- 分类预测一个离散类别（猫狗之类的）
  - MNIST：手写数字识别
  - ImageNet：自然物体识别
  - Kaggle蛋白质显微镜图片分类
  - 恶意软件分类9类
  - 文字：恶意评论
  
|回归|分类|
|---|---|
|1.单连续数值输出|1.通常多个输出|
|2.自然区间$R$|2.输出i是预测为第i类的置信度|
|3.跟真实值的区别作为损失|  |

## 从回归到多类分类——均方误差

- 对类别进行一位有效编码
  $$y=[y_1,y_2,...,y_n]^T$$
  $$y_i=\left\{
	\begin{array}{ll}
		1&if \ \ i=y\\
		0&otherwise
	\end{array}\right.$$
- 使用均方误差训练
- 最大值作为预测

## Softmax和交叉熵损失
- 交叉熵通常用来衡量两个概率的区别$H(p,q)=-\sum_{i}y_ilog{\hat{y_i}}=-log\hat{y}_y$

## 损失函数
### L2 Loss 均方损失
$l(y,y^')=\frac{1}{2} (y-y^')^2$
似然误差


### L1 Loss 绝对值损失函数
预测值-真实值的绝对值

稳定比较好，但是导数不平滑，优化到后期会不稳定

### Huber's Robust Loss 哈勃鲁棒损失
绝对值误差大于某个阈值时会进行函数切换

